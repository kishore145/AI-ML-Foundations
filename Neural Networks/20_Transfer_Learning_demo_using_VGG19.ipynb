{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "20-Transfer Learning demo using VGG19.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN04evmCeEf1J6malEOwSS0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kishore145/AI-ML-Foundations/blob/master/Neural%20Networks/20_Transfer_Learning_demo_using_VGG19.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUk3yKAqoPT7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load dependencies\n",
        "from tensorflow.keras.applications.vgg19 import VGG19 # Import VGG19\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzf16TI3pB8t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "ce75602d-c960-4dea-a699-dff7156fcac2"
      },
      "source": [
        "# Load pretrained VGG19 model\n",
        "vgg19 = VGG19(weights='imagenet',\n",
        "              include_top=False,\n",
        "              input_shape = (224,224,3), \n",
        "              pooling = None)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80142336/80134624 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68aPtonfp4lx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Freeze all layers in VGG19 to preserve learning from imagenet\n",
        "for layer in vgg19.layers:\n",
        "  layer.trainable = False\n",
        "  "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxSsblrHqL_4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Adding custom classification layers\n",
        "# Instantiate a sequential model with vgg19 layers\n",
        "model = Sequential()\n",
        "model.add(vgg19)\n",
        "\n",
        "# Add custom classification layer on top\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(2, activation = 'softmax'))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hK2dFpQqmY7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "outputId": "5326a91e-9c05-453d-95c8-145126dc1ee1"
      },
      "source": [
        "model.summary()\n",
        "# As seen on the below data, the number of trainable parameters is only 50k\n",
        "# This shows that we are utilizing the pre-trained weights for detecting low  \n",
        "# level features of the image and only training higher abstract layer to differentiate\n",
        "# hot dog and not hot dog."
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg19 (Model)                (None, 7, 7, 512)         20024384  \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 50178     \n",
            "=================================================================\n",
            "Total params: 20,074,562\n",
            "Trainable params: 50,178\n",
            "Non-trainable params: 20,024,384\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTQGXHRGqn7b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='nadam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIZ7-DwIq1Ej",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "outputId": "0ff47b8e-e9e3-4b88-e812-8f2095203aa8"
      },
      "source": [
        "# Data preparation for model training\n",
        "# You can comment out the two lines of code below if you executed them on\n",
        "# a previous run of the notebook. The wget command downloads the data and the \n",
        "# tar command extracts the data from a compressed file format. \n",
        "! wget -c https://www.dropbox.com/s/86r9z1kb42422up/hot-dog-not-hot-dog.tar.gz\n",
        "! tar -xzf hot-dog-not-hot-dog.tar.gz"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-29 06:03:01--  https://www.dropbox.com/s/86r9z1kb42422up/hot-dog-not-hot-dog.tar.gz\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.3.1, 2620:100:6018:1::a27d:301\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.3.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/86r9z1kb42422up/hot-dog-not-hot-dog.tar.gz [following]\n",
            "--2020-06-29 06:03:01--  https://www.dropbox.com/s/raw/86r9z1kb42422up/hot-dog-not-hot-dog.tar.gz\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucb0c4768d62b64c7a7555eb7370.dl.dropboxusercontent.com/cd/0/inline/A6htMTXUd2b5yHrsevxAEA8zTkoNApu9KKiY0uKVVS2GPiB2qXbYp1S12TWO_h6jAm6BLW4J0k9dFvGmgo8bwnbc4WnYhAvTMIfHV-dI2iXd7XejqbOuCO7kitWYa12FbB8/file# [following]\n",
            "--2020-06-29 06:03:02--  https://ucb0c4768d62b64c7a7555eb7370.dl.dropboxusercontent.com/cd/0/inline/A6htMTXUd2b5yHrsevxAEA8zTkoNApu9KKiY0uKVVS2GPiB2qXbYp1S12TWO_h6jAm6BLW4J0k9dFvGmgo8bwnbc4WnYhAvTMIfHV-dI2iXd7XejqbOuCO7kitWYa12FbB8/file\n",
            "Resolving ucb0c4768d62b64c7a7555eb7370.dl.dropboxusercontent.com (ucb0c4768d62b64c7a7555eb7370.dl.dropboxusercontent.com)... 162.125.3.15, 2620:100:6018:15::a27d:30f\n",
            "Connecting to ucb0c4768d62b64c7a7555eb7370.dl.dropboxusercontent.com (ucb0c4768d62b64c7a7555eb7370.dl.dropboxusercontent.com)|162.125.3.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/A6h7W4N2w5rrukzhOyTEx4JMOkD8K5CYoc7MvTw1MFPf8B4n1nO3eAXrxZNgz0GX41Yjoka_sI16SCulpdBdbHcgk8Uucx_aTv6Q1Lij4_AFR-G7GgIr2Pf2wYCUbroN-z6KNQjGv5JglwFMlHwaozoA9wjZpJjfymlglBBirvuhsPFjH6Nf697H8vcOp69xlvRl7HjiEshMMXu3WlZ87Ga7lBbq-9xMDU-MTpHomerQ6RgaTBmPq-PzC8n-7sUeF3504Ivr4fNrge5j5fgNgPrQgZiluwJmG7syeqvcr--LYjU7CSiNf063P3oCT_A4sMl_x8WugWB29v5vi-v3ktJ90D0WcD1yFYph1IrVDijrsA/file [following]\n",
            "--2020-06-29 06:03:02--  https://ucb0c4768d62b64c7a7555eb7370.dl.dropboxusercontent.com/cd/0/inline2/A6h7W4N2w5rrukzhOyTEx4JMOkD8K5CYoc7MvTw1MFPf8B4n1nO3eAXrxZNgz0GX41Yjoka_sI16SCulpdBdbHcgk8Uucx_aTv6Q1Lij4_AFR-G7GgIr2Pf2wYCUbroN-z6KNQjGv5JglwFMlHwaozoA9wjZpJjfymlglBBirvuhsPFjH6Nf697H8vcOp69xlvRl7HjiEshMMXu3WlZ87Ga7lBbq-9xMDU-MTpHomerQ6RgaTBmPq-PzC8n-7sUeF3504Ivr4fNrge5j5fgNgPrQgZiluwJmG7syeqvcr--LYjU7CSiNf063P3oCT_A4sMl_x8WugWB29v5vi-v3ktJ90D0WcD1yFYph1IrVDijrsA/file\n",
            "Reusing existing connection to ucb0c4768d62b64c7a7555eb7370.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 46736828 (45M) [application/octet-stream]\n",
            "Saving to: ‘hot-dog-not-hot-dog.tar.gz’\n",
            "\n",
            "hot-dog-not-hot-dog 100%[===================>]  44.57M  66.2MB/s    in 0.7s    \n",
            "\n",
            "2020-06-29 06:03:04 (66.2 MB/s) - ‘hot-dog-not-hot-dog.tar.gz’ saved [46736828/46736828]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARBIrfjcq_kk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instantiate two image generator classes:\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255, \n",
        "    data_format='channels_last',\n",
        "    rotation_range=30,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='reflect')\n",
        "\n",
        "valid_datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255,\n",
        "    data_format='channels_last')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YB5LXpWsHc8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the batch size:\n",
        "batch_size=32"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HR0GYvwvsKaR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ca20eb2a-7fa3-4af3-ed24-889da8abccc3"
      },
      "source": [
        "# Define the train and validation generators: \n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    directory='./hot-dog-not-hot-dog/train', \n",
        "    target_size=(224, 224),\n",
        "    classes=['hot_dog','not_hot_dog'],\n",
        "    class_mode='categorical',\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    seed=42)\n",
        "\n",
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "    directory='./hot-dog-not-hot-dog/test',\n",
        "    target_size=(224, 224),\n",
        "    classes=['hot_dog','not_hot_dog'],\n",
        "    class_mode='categorical',\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    seed=42)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 498 images belonging to 2 classes.\n",
            "Found 500 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivhpDiOSs9Pn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        },
        "outputId": "f5de70d4-5182-415e-942a-abc86878b473"
      },
      "source": [
        "# Fit pre-trained model\n",
        "model.fit(train_generator, steps_per_epoch=15, \n",
        "                    epochs=16, validation_data=valid_generator, \n",
        "                    validation_steps=15)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/16\n",
            "15/15 [==============================] - 575s 38s/step - loss: 1.1069 - accuracy: 0.5579 - val_loss: 0.5314 - val_accuracy: 0.7250\n",
            "Epoch 2/16\n",
            "15/15 [==============================] - 581s 39s/step - loss: 1.0284 - accuracy: 0.6083 - val_loss: 0.4957 - val_accuracy: 0.7646\n",
            "Epoch 3/16\n",
            "15/15 [==============================] - 573s 38s/step - loss: 0.7846 - accuracy: 0.6781 - val_loss: 0.4944 - val_accuracy: 0.7812\n",
            "Epoch 4/16\n",
            "15/15 [==============================] - 582s 39s/step - loss: 0.7029 - accuracy: 0.6931 - val_loss: 0.5706 - val_accuracy: 0.7417\n",
            "Epoch 5/16\n",
            "15/15 [==============================] - 574s 38s/step - loss: 0.5648 - accuracy: 0.7597 - val_loss: 1.4239 - val_accuracy: 0.5625\n",
            "Epoch 6/16\n",
            "15/15 [==============================] - 577s 38s/step - loss: 0.7187 - accuracy: 0.7189 - val_loss: 0.6226 - val_accuracy: 0.7333\n",
            "Epoch 7/16\n",
            "15/15 [==============================] - 573s 38s/step - loss: 0.5862 - accuracy: 0.7747 - val_loss: 0.6268 - val_accuracy: 0.7333\n",
            "Epoch 8/16\n",
            "15/15 [==============================] - 572s 38s/step - loss: 0.3830 - accuracy: 0.8476 - val_loss: 0.4617 - val_accuracy: 0.7917\n",
            "Epoch 9/16\n",
            "15/15 [==============================] - 572s 38s/step - loss: 0.3815 - accuracy: 0.8305 - val_loss: 0.4566 - val_accuracy: 0.8125\n",
            "Epoch 10/16\n",
            "15/15 [==============================] - 572s 38s/step - loss: 0.4610 - accuracy: 0.8069 - val_loss: 1.7742 - val_accuracy: 0.5667\n",
            "Epoch 11/16\n",
            "15/15 [==============================] - 572s 38s/step - loss: 0.3714 - accuracy: 0.8562 - val_loss: 0.6486 - val_accuracy: 0.7375\n",
            "Epoch 12/16\n",
            "15/15 [==============================] - 571s 38s/step - loss: 0.2988 - accuracy: 0.8734 - val_loss: 0.6281 - val_accuracy: 0.7479\n",
            "Epoch 13/16\n",
            "15/15 [==============================] - 574s 38s/step - loss: 0.2454 - accuracy: 0.8927 - val_loss: 0.5046 - val_accuracy: 0.7917\n",
            "Epoch 14/16\n",
            "15/15 [==============================] - 571s 38s/step - loss: 0.2907 - accuracy: 0.8691 - val_loss: 0.4816 - val_accuracy: 0.7917\n",
            "Epoch 15/16\n",
            "15/15 [==============================] - 579s 39s/step - loss: 0.3092 - accuracy: 0.8792 - val_loss: 0.5333 - val_accuracy: 0.8042\n",
            "Epoch 16/16\n",
            "15/15 [==============================] - 571s 38s/step - loss: 0.2211 - accuracy: 0.9163 - val_loss: 0.4691 - val_accuracy: 0.8062\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f43c3b76278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5v5_dcQuR2z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# With transfer learning, we can get reasonable accuracy with as little as 16 epochs\n",
        "# and can train it on CPU for experimentation. "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}